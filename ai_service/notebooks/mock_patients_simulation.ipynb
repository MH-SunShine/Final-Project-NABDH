{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c59f2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for dataset at: c:\\Users\\dell\\OneDrive\\Desktop\\Final-Project-NABDH\\ai_service\\data\\Dataset.csv\n",
      "âœ… Saved clean patient_1_cleaned.csv to: c:\\Users\\dell\\OneDrive\\Desktop\\Final-Project-NABDH\\ai_service\\data\\patients\\patient_1_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "# old patients simulation\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# === Step 1: Set up paths ===\n",
    "\n",
    "# Get absolute path to this script's folder\n",
    "try:\n",
    "    # Use __file__ if available\n",
    "    project_root = os.path.dirname(os.path.abspath(__file__))\n",
    "except NameError:\n",
    "    # Fallback to the current working directory\n",
    "    project_root = os.getcwd()\n",
    "\n",
    "# point to the parent directory (ai_service)\n",
    "project_root = os.path.dirname(project_root)\n",
    "\n",
    "# Path to dataset\n",
    "dataset_path = os.path.join(project_root, \"data\", \"Dataset.csv\")\n",
    "\n",
    "# Debugging: Print the resolved path\n",
    "print(\"Looking for dataset at:\", dataset_path)\n",
    "\n",
    "# Path to save extracted patient data (new folder)\n",
    "output_dir = os.path.join(project_root, \"data\", \"patients\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# === Step 2: Read and clean dataset ===\n",
    "\n",
    "# Read raw CSV lines\n",
    "try:\n",
    "    with open(dataset_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{dataset_path}' was not found. Please check the path.\")\n",
    "    exit(1)\n",
    "\n",
    "# Clean header and data lines\n",
    "header = lines[0].replace('\"', '').strip().split(\",\")\n",
    "data = [line.replace('\"', '').strip().split(\",\") for line in lines[1:]]\n",
    "\n",
    "# Build DataFrame\n",
    "df = pd.DataFrame(data, columns=header)\n",
    "\n",
    "# Convert all numeric columns (except ID)\n",
    "for col in df.columns:\n",
    "    if col != \"seqn\":\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "# === Step 3: Extract patient row and save it ===\n",
    "\n",
    "# Get patient row number\n",
    "patient_1 = df.iloc[[6000]]\n",
    "\n",
    "# Save to CSV\n",
    "patient_path = os.path.join(output_dir, \"patient_1_cleaned.csv\")\n",
    "patient_1.to_csv(patient_path, index=False)\n",
    "\n",
    "\n",
    "print(\"âœ… Saved clean patient_1_cleaned.csv to:\", patient_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb8567f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded: c:\\Users\\dell\\OneDrive\\Desktop\\Final-Project-NABDH\\ai_service\\data\\patients\\patient_1_cleaned.csv\n",
      "ðŸ§¬ Abnormal markers for this patient '''Patient1''':\n",
      "\n",
      "â€¢ lbxsalâ†“\n",
      "â€¢ lbdsalsiâ†“\n",
      "â€¢ lbxsapsiâ†“\n",
      "â€¢ lbxsldsiâ†“\n",
      "â€¢ lbxsclsiâ†‘\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Go up one level from 'notebooks' to project root\n",
    "base_dir = os.path.dirname(os.getcwd())  # get out of 'notebooks'\n",
    "patient_path = os.path.join(base_dir, \"data\", \"patients\", \"patient_1_cleaned.csv\")\n",
    "\n",
    "# === 1. Load the patient CSV\n",
    "patient = pd.read_csv(patient_path)\n",
    "\n",
    "print(\"âœ… Loaded:\", patient_path)\n",
    "\n",
    "# === 2. Define normal ranges (copy-paste from Apriori general script) ===\n",
    "normal_ranges = {\n",
    "    'lbxsal': (135, 145), 'lbdsalsi': (135, 145), 'lbxsassi': (10, 40), 'lbxsapsi': (44, 147),\n",
    "    'lbxsbu': (7, 20), 'lbdsbusi': (2.5, 7.1), 'lbxsca': (8.5, 10.2), 'lbdscasi': (2.12, 2.55),\n",
    "    'lbxsck': (22, 198), 'lbxsch': (0, 200), 'lbdschsi': (0, 5.17), 'lbxsc3si': (22, 29),\n",
    "    'lbxscr': (0.74, 1.35), 'lbdscrsi': (65.4, 119.3), 'lbxsgtsi': (9, 48), 'lbxsgl': (70, 99),\n",
    "    'lbdsglsi': (3.9, 5.5), 'lbxsir': (60, 170), 'lbdsirsi': (10.7, 30.4), 'lbxsldsi': (140, 280),\n",
    "    'lbxsph': (2.5, 4.5), 'lbdsphsi': (0.81, 1.45), 'lbxstb': (0.1, 1.2), 'lbdstbsi': (1.71, 20.5),\n",
    "    'lbxstp': (6.0, 8.3), 'lbdstpsi': (60, 83), 'lbxsua': (3.5, 7.2), 'lbdsuasi': (208, 428),\n",
    "    'lbxsnasi': (135, 145), 'lbxsksi': (3.5, 5.1), 'lbxsclsi': (98, 107), 'lbxsossi': (275, 295),\n",
    "    'lbxsgb': (2.0, 3.5), 'lbdsgbsi': (20, 35), 'lbxstr': (0, 150), 'lbdstrsi': (0, 1.7),\n",
    "    'lbxsatsi': (20, 55)\n",
    "}\n",
    "\n",
    "# === 3. Our Normalize function ===\n",
    "def normalize(val, low, high):\n",
    "    if val < low:\n",
    "        return -1\n",
    "    elif val > high:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "# === 4. Analyze abnormal markers ===\n",
    "# up arrow for 1 and updown for -1\n",
    "abnormal_markers = []\n",
    "\n",
    "for col, (low, high) in normal_ranges.items():\n",
    "    val = pd.to_numeric(patient[col].values[0], errors=\"coerce\")\n",
    "    status = normalize(val, low, high)\n",
    "\n",
    "    if status == -1:\n",
    "        abnormal_markers.append(f\"{col}â†“\")\n",
    "    elif status == 1:\n",
    "        abnormal_markers.append(f\"{col}â†‘\")\n",
    "\n",
    "# === 5. Show the result ===\n",
    "print(\"ðŸ§¬ Abnormal markers for this patient '''Patient1''':\\n\")\n",
    "for marker in abnormal_markers:\n",
    "    print(\"â€¢\", marker)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eecb83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Œ Matching Rules for This Patient:\n",
      "\n",
      "\n",
      "âœ… Matching rules saved in 'matched_rules_for_patient_1.txt'\n"
     ]
    }
   ],
   "source": [
    "# matching the extracted abnormal marks with general rules\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Load abnormal markers\n",
    "patient_markers = abnormal_markers\n",
    "\n",
    "# 2. Load generated Apriori rules\n",
    "with open(\"generated_rules.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    rules = f.readlines()\n",
    "\n",
    "# 3. Filter rules that only match patient markers\n",
    "matching_rules = []\n",
    "\n",
    "for rule in rules:\n",
    "    rule = rule.strip()\n",
    "    if not rule:\n",
    "        continue\n",
    "\n",
    "    # Extract antecedents from rule\n",
    "    if \"If [\" in rule and \"] â†’\" in rule:\n",
    "        ant_section = rule.split(\"If [\")[1].split(\"]\")[0]\n",
    "        antecedents = [x.strip() for x in ant_section.split(\",\")]\n",
    "\n",
    "        # Check if any antecedents match patient markers\n",
    "        if any(a in patient_markers for a in antecedents):\n",
    "            matching_rules.append(rule)\n",
    "\n",
    "# 4. Display results\n",
    "print(\"\\nðŸ“Œ Matching Rules for This Patient:\\n\")\n",
    "for r in matching_rules:\n",
    "    print(\"â€¢\", r)\n",
    "\n",
    "# 5. Optional: Save matching rules to a file\n",
    "with open(\"matched_rules_for_patient_1.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for r in matching_rules:\n",
    "        f.write(r + \"\\n\")\n",
    "\n",
    "print(\"\\nâœ… Matching rules saved in 'matched_rules_for_patient_1.txt'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
