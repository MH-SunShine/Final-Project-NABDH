{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90628918-f1d1-4f0d-b971-d7e639e2c80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6549, 39)\n"
     ]
    }
   ],
   "source": [
    "# --- üåü Step 1: Import libraries\n",
    "import pandas as pd\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "# Ignore RuntimeWarnings for clean output\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# --- üåü Step 2: Load and Clean the Dataset\n",
    "\n",
    "# Read manually to fix formatting issues\n",
    "with open(\"Dataset.csv\", \"r\", encoding=\"utf-8\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Split headers and data + clean them\n",
    "header = lines[0].replace('\"', '').strip().split(',')\n",
    "data = [line.replace('\"', '').strip().split(',') for line in lines[1:]] \n",
    "df = pd.DataFrame(data, columns=header) # cleaned data frame\n",
    "\n",
    "# 5. dataset overview\n",
    "# print(df.shape) # number of rows and columns\n",
    "# print(df.columns) # list all columns names\n",
    "# print(df.isnull().sum()) # sum of null values\n",
    "# df.head() # display first 5 rows\n",
    "# (df.isnull().sum() / len(df) * 100).sort_values(ascending=False)\n",
    "# print(df.info()) # overview about the dataset\n",
    "# print(df.dtypes) # Check data types of columns\n",
    "# print(df.columns.tolist()) # check column names\n",
    "\n",
    "# Convert from objects to numeric columns\n",
    "numeric_columns = [\n",
    "    \"lbxsal\", \"lbdsalsi\", \"lbxsatsi\", \"lbxsassi\", \"lbxsapsi\",\n",
    "    \"lbxsbu\", \"lbdsbusi\", \"lbxsca\", \"lbdscasi\", \"lbxsck\", \"lbxsch\",\n",
    "    \"lbdschsi\", \"lbxsc3si\", \"lbxscr\", \"lbdscrsi\", \"lbxsgtsi\", \"lbxsgl\",\n",
    "    \"lbdsglsi\", \"lbxsir\", \"lbdsirsi\", \"lbxsldsi\", \"lbxsph\", \"lbdsphsi\",\n",
    "    \"lbxstb\", \"lbdstbsi\", \"lbxstp\", \"lbdstpsi\", \"lbxsua\", \"lbdsuasi\",\n",
    "    \"lbxsnasi\", \"lbxsksi\", \"lbxsclsi\", \"lbxsossi\", \"lbxsgb\", \"lbdsgbsi\",\n",
    "    \"lbxstr\", \"lbdstrsi\"\n",
    "]\n",
    "\n",
    "for col in numeric_columns:\n",
    "    df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "# Drop 'seqn' (ID)\n",
    "df = df.drop(columns=['seqn'])\n",
    "\n",
    "# --- üåü Step 3: Normalize the values into -1, 0, 1\n",
    "# standard normal ranges\n",
    "normal_ranges = {\n",
    "    'lbxsal': (135, 145), 'lbdsalsi': (135, 145), 'lbxsassi': (10, 40), 'lbxsapsi': (44, 147),\n",
    "    'lbxsbu': (7, 20), 'lbdsbusi': (2.5, 7.1), 'lbxsca': (8.5, 10.2), 'lbdscasi': (2.12, 2.55),\n",
    "    'lbxsck': (22, 198), 'lbxsch': (0, 200), 'lbdschsi': (0, 5.17), 'lbxsc3si': (22, 29),\n",
    "    'lbxscr': (0.74, 1.35), 'lbdscrsi': (65.4, 119.3), 'lbxsgtsi': (9, 48), 'lbxsgl': (70, 99),\n",
    "    'lbdsglsi': (3.9, 5.5), 'lbxsir': (60, 170), 'lbdsirsi': (10.7, 30.4), 'lbxsldsi': (140, 280),\n",
    "    'lbxsph': (2.5, 4.5), 'lbdsphsi': (0.81, 1.45), 'lbxstb': (0.1, 1.2), 'lbdstbsi': (1.71, 20.5),\n",
    "    'lbxstp': (6.0, 8.3), 'lbdstpsi': (60, 83), 'lbxsua': (3.5, 7.2), 'lbdsuasi': (208, 428),\n",
    "    'lbxsnasi': (135, 145), 'lbxsksi': (3.5, 5.1), 'lbxsclsi': (98, 107), 'lbxsossi': (275, 295),\n",
    "    'lbxsgb': (2.0, 3.5), 'lbdsgbsi': (20, 35), 'lbxstr': (0, 150), 'lbdstrsi': (0, 1.7),\n",
    "    'lbxsatsi': (20, 55)\n",
    "}\n",
    "# function to normalize\n",
    "def normalize(val, low, high):\n",
    "    if val < low:\n",
    "        return -1\n",
    "    elif val > high:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "normalized_df = pd.DataFrame()\n",
    "\n",
    "for col, (low, high) in normal_ranges.items():\n",
    "    normalized_df[col] = df[col].apply(lambda x: normalize(x, low, high))\n",
    "\n",
    "# --- üåü Step 4: Create Transactions\n",
    "# function to label values (up - down)\n",
    "def get_label(col, val):\n",
    "    if val == -1:\n",
    "        return f\"{col}‚Üì\"\n",
    "    elif val == 1:\n",
    "        return f\"{col}‚Üë\"\n",
    "    else:\n",
    "        return None\n",
    "# create transactions\n",
    "transactions = []\n",
    "for _, row in normalized_df.iterrows():\n",
    "    items = [get_label(col, row[col]) for col in normalized_df.columns]\n",
    "    transaction = list(filter(None, items))  # Remove None\n",
    "    transactions.append(transaction)\n",
    "\n",
    "# --- üåü Step 5: Apply Apriori Algorithm\n",
    "\n",
    "# Encode transactions\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(transactions).transform(transactions)\n",
    "df_encoded = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "# Run Apriori\n",
    "frequent_itemsets = apriori(df_encoded, min_support=0.02, use_colnames=True)\n",
    "\n",
    "# Create rules\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.7)\n",
    "\n",
    "# --- üåü Step 6: Clean & Present Rules\n",
    "\n",
    "# Filter strong rules\n",
    "strong_rules = rules[(rules['confidence'] >= 0.7) & (rules['lift'] >= 1)]\n",
    "\n",
    "# Sort by confidence and lift\n",
    "strong_rules = strong_rules.sort_values(by=['confidence', 'lift'], ascending=False)\n",
    "\n",
    "# Beautify the output\n",
    "print(\"\\n‚úÖ Strong Association Rules for Medical Analysis:\\n\")\n",
    "for idx, rule in strong_rules.iterrows():\n",
    "    ant = ', '.join(list(rule['antecedents']))\n",
    "    con = ', '.join(list(rule['consequents']))\n",
    "    print(f\"If [{ant}] ‚Üí Then [{con}] (Support: {rule['support']:.2f}, Confidence: {rule['confidence']:.2f}, Lift: {rule['lift']:.2f})\")\n",
    "\n",
    "\n",
    "# --- üåü Step 7: Format and Save Rules for LLM\n",
    "\n",
    "formatted_rules = []\n",
    "\n",
    "for _, row in strong_rules.iterrows():\n",
    "    antecedent = ', '.join(list(row['antecedents']))\n",
    "    consequent = ', '.join(list(row['consequents']))\n",
    "    support = round(row['support'], 3)\n",
    "    confidence = round(row['confidence'], 3)\n",
    "    lift = round(row['lift'], 2)\n",
    "\n",
    "    rule = (\n",
    "        f\"If a patient has [{antecedent}], they likely also have [{consequent}]. \"\n",
    "        f\"(Support: {support}, Confidence: {confidence}, Lift: {lift})\"\n",
    "    )\n",
    "    formatted_rules.append(rule)\n",
    "\n",
    "# ‚úÖ Save to TXT\n",
    "with open(\"generated_rules.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for rule in formatted_rules:\n",
    "        f.write(rule + \"\\n\")\n",
    "\n",
    "print(\"‚úÖ Saved Apriori rules to 'rules_for_llm.txt'\")\n",
    "\n",
    "\n",
    "\n",
    "# üé® Step 3: Visualize and save association graph\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if not strong_rules.empty:\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    for idx, rule in strong_rules.iterrows():\n",
    "        for antecedent in rule['antecedents']:\n",
    "            for consequent in rule['consequents']:\n",
    "                G.add_edge(antecedent, consequent, weight=rule['confidence'])\n",
    "\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    pos = nx.spring_layout(G, k=0.5, seed=42)\n",
    "    nx.draw(G, pos, with_labels=True,\n",
    "            node_color='lightblue', \n",
    "            node_size=2000, \n",
    "            edge_color='gray', \n",
    "            arrows=True, \n",
    "            arrowsize=25, \n",
    "            font_size=12)\n",
    "\n",
    "    plt.title('ü©∫ Medical Association Rules Network', fontsize=16)\n",
    "    \n",
    "    # üì∏ Save the graph automatically\n",
    "    plt.savefig(\"AssociationRulesGraph.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\n‚úÖ Graph saved as 'AssociationRulesGraph.png' successfully!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No graph to display because no strong rules were found.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0432ed2-8fce-43cd-95ad-2b64452fcc06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945c0111-a3d2-42f6-aed6-b7ef2a724fad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
